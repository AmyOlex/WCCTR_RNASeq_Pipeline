# SoupX Contamination Adjustment and Report Generation Script
# Author: Amy Olex
# Date: 3/18/2025
# Version: 1.0

# Disclaimer:
# This file was generated by the author with assistance from MS Copilot March 2025.

# Description:
# This script performs ambient RNA contamination adjustment using the SoupX package
# for multiple samples and generates a comprehensive HTML report for all samples.
# The report includes contamination plots, post rho values, and flags samples with
# a post rho value greater than twice the rho prior value.

# Usage:
# 1. Ensure the necessary packages are installed: rmarkdown, SoupX, Seurat.
# 2. Define the 'toProcess' data frame with sample names and paths to raw 10X data.
# 3. Set the 'savedir' variable to the directory where reports will be saved.
# 4. Run the script to generate the HTML report.

# Example:
# toProcess <- data.frame(SampleName = c("Sample1", "Sample2"), raw10Xdata = c("path/to/sample1", "path/to/sample2"))
# savedir <- "path/to/save/reports/"
# generate_report(toProcess, savedir)

# Notes:
# - Adjust the parameters in SoupX (tfidfMin, soupQuantile) if necessary to optimize contamination correction.
# - Validate the results by checking known marker genes and their expression patterns.
# - Consult with an expert if needed to confirm the appropriateness of the chosen cutoff and adjustments.


library(rmarkdown)
library(SoupX)
library(Seurat)
library(doParallel)
library(foreach)
library("hdf5r")
library(DropletUtils)
library(ggplot2)


## define functions
add_soup_groups <- function (sobj){
  sobj <- NormalizeData(sobj, verbose = FALSE)
  sobj <- FindVariableFeatures(sobj, selection.method = "vst", nfeatures = 2000, verbose=FALSE)
  sobj <- ScaleData(sobj, verbose=FALSE)
  sobj <- RunPCA(sobj, npcs = 20, verbose = FALSE)
  sobj <- FindNeighbors(sobj, dims=1:20) #1:20
  sobj <- FindClusters(sobj, resolution = 0.4, verbose=FALSE)
  sobj <- RunUMAP(sobj, dims = 1:15)
  sobj$soup_group <- sobj@meta.data[['seurat_clusters']]
  return(sobj)
}

save_gene_plots <- function(sc1, out, intersected_genes, sample_name, sample_dir) {

  # Loop through each gene in the intersected_genes list
  for (gene in intersected_genes) {
    #print(gene)
    # Define file paths for the images
    change_map_file <- file.path(sample_dir, paste0(gene, "_plotChangeMap.png"))
    marker_map_file <- file.path(sample_dir, paste0(gene, "_plotMarkerMap.png"))

    # Save plotChangeMap image
    png(filename = change_map_file, width = 1000, height = 600, res = 150)
      p1 = plotChangeMap(sc1, out, gene)
      plot(p1)
    dev.off()

    # Save plotMarkerMap image
    png(filename = marker_map_file, width = 1000, height = 600, res = 150)
      p2 = plotMarkerMap(sc1, gene)
      plot(p2)
    dev.off()
  }

  print(paste("Images saved in directory:", sample_dir))
}

# Function to generate HTML report for all samples
generate_report <- function(toProcess, savedir, numCores) {

  # Set up parallel backend
  #cl <- makeCluster(numCores)
  #registerDoParallel(cl)
  ## , .packages = c("SoupX", "Seurat", "rmarkdown", "ggplot2"),
  ## .export = c("add_soup_groups", "save_gene_plots")

  results_list <- list()

  for(i in 1:nrow(toProcess)) {

    print(paste("Importing data for row", i, "from sample", toProcess[i,"SampleName"]))
    skip_sample = FALSE #will get set to TRUE if this sample needs to be skipped.

    if(toProcess[i,"DataType"] == "Seurat"){
      print(paste0(toProcess[i,"SampleName"], ": Loading Seurat h5 File..."))
      library(SeuratDisk)
      if(file.exists(trimws(toProcess[i,"SamplePath"]))){
        h5 <- LoadH5Seurat(trimws(toProcess[i,"SamplePath"]))
      } else{
        print(paste("ERROR, file not found: ",toProcess[i,"SampleName"]) )
      }
    } else if(toProcess[i,"DataType"] == "10X"){
      print(paste0(toProcess[i,"SampleName"], ": Loading 10X feature matrix..."))
      # Load the data set and create the Seurat object
      sc.data <- Read10X(data.dir = toProcess[i,"SamplePath"])  ## must point to the filtered_feature_bc_matrix directory.
      # Initialize the Seurat object
      h5 <- CreateSeuratObject(counts = sc.data, project = toProcess[i,"SampleName"], min.cells = 0, min.features = 0)

    } else{
      print("Error unknown data type.")
      quit(1)
    }

    sample_name <- toProcess[i, "SampleName"]

    # Create sample results dir
    sample_dir <- paste0(savedir,sample_name, "/")

    ## add Soup Groups to filtered feature data
    h5 <- add_soup_groups(h5)

    ##load in unfiltered raw data (must be in 10X format)
    raw_10x <- Read10X(data.dir = toProcess[i,"raw10Xdata"])
    rownames(raw_10x) <- gsub("_", "-", rownames(raw_10x))

    sc1 <- SoupChannel(raw_10x, GetAssayData(h5, assay = "RNA", layer = "counts"), calcSoupProfile=FALSE)
    sc1 <- setClusters(sc1, h5$soup_group)
    sc1 = estimateSoup(sc1,soupRange=c(0,200))

    w = which(sc1$nDropUMIs > 0 & sc1$nDropUMIs < 100)
    soupProfile = data.frame(row.names = rownames(raw_10x), est = rowSums(raw_10x[, w, drop = FALSE])/sum(raw_10x[,w]), counts = rowSums(raw_10x[, w, drop = FALSE]))


    if (any(is.na(sc1$soupProf$est)) || any(is.nan(sc1$soupProf$est))) {
      sc1$soupProf$est <- na.omit(sc1$soupProf$est)
    }

    tryCatch({
      png(file = paste0(savedir, sample_name, "_SoupXestimates.png"), width = 1000, height = 500, res = 100)
        sc1 <- autoEstCont(sc1, doPlot = TRUE)
      dev.off()
    }, error = function(e) {
      print(conditionMessage(e))
      warning(paste0("Warning: skipping sample due to high homogeneity across soup and cells: ", sample_name))
      skip_sample <<- TRUE
    })

    if(!skip_sample){

      print("Adjusting ambient RNA in sample...")

      # Create a directory named after the sample
      dir.create(sample_dir, showWarnings = FALSE)

      ## add in UMAP coordinates
      umap_coords <- Embeddings(h5, "umap")
      umap_df <- as.data.frame(umap_coords)
      umap_df$cell_id <- rownames(umap_df)
      sc1 <- setDR(sc1, umap_df[, 1:2])

      ## Calculate adjusted
      out = adjustCounts(sc1)

      ## Identify genes where 100% of expression was removed from at least 1 cell
      ## AND more than 50 cells had a SoupFrac greater than 75%.
      cntSoggy = rowSums(sc1$toc > 0) #Number of cells with greater than zero counts PRE
      cntStrained = rowSums(out > 0) #Number of cells with greater than zero counts AFTER
      cntDiff = (cntSoggy - cntStrained) #Number of cells that were zeroed out
      ## Fraction of cells that had gene zeroed out relative to the number of cells that had expression PRE.
      ZeroedOutGenes = names(cntSoggy)[na.omit((cntDiff/cntSoggy) == 1)] #Identify all genes that had a 100% reduction to zero.

      # Calculate SoupFrac for each gene in each cell
      soup_frac <- (sc1$toc - out) / sc1$toc

      # Set a threshold for SoupFrac and the minimum number of cells
      soup_frac_threshold <- 0.75
      # Calculate the total number of cells in the sample
      total_cells <- ncol(sc1$toc)

      # Set the cell threshold to 10% of the total number of cells
      cell_threshold <- ceiling(0.05 * total_cells)


      # Count the number of cells for each gene where SoupFrac is greater than the threshold
      num_cells_above_threshold <- rowSums(soup_frac > soup_frac_threshold, na.rm = TRUE)

      # Identify genes that meet the criteria
      filtered_genes <- names(num_cells_above_threshold)[num_cells_above_threshold >= cell_threshold]
      # Intersect the filtered genes with ZeroedOutGenes
      union_genes <- union(filtered_genes, ZeroedOutGenes)

      ## Save the list of affected genes
      # Calculate the average AvgSoupFrac for the unioned genes, but only use the cells that express each gene.
      #average_soup_frac <- rowMeans(soup_frac, na.rm = TRUE)

      average_soup_frac <- apply(soup_frac, 1, function(row) {
        non_zero_values <- row[row != 0]
        mean(non_zero_values, na.rm = TRUE)
      })

      genes_df <- data.frame(
        Gene = names(average_soup_frac),
        AvgSoupFrac = average_soup_frac,
        ZeroedOut = ifelse(names(average_soup_frac) %in% ZeroedOutGenes, "yes", "no"),
        HighSoupFrac = ifelse(names(average_soup_frac) %in% filtered_genes, "yes", "no")
      )

      # Filter the dataframe to include only genes in the union_genes list
      filtered_genes_df <- genes_df[genes_df$Gene %in% union_genes, ]
      # Sort the dataframe by the AvgSoupFrac column from highest to lowest
      sorted_genes_df <- filtered_genes_df[order(filtered_genes_df$AvgSoupFrac, decreasing = TRUE), ]


      # Save the data frame to a CSV file if there is any data to save
      if(length(sorted_genes_df$Gene) > 0){
        write.csv(sorted_genes_df, file = paste0(sample_dir, sample_name, "_TopAffectedGenes.csv"), row.names = FALSE)
        save_gene_plots(sc1, out, sorted_genes_df$Gene[1:min(length(sorted_genes_df$Gene), 20)], sample_name, sample_dir)
      } else{
        warning(paste0("No genes matching criteria for sample ", sample_name))
      }


      # Compile data for report
      post_rho <- sc1$fit$rhoEst
      rho_prior <- sc1$fit$priorRho
      flag <- ifelse(post_rho > 2 * rho_prior, "Flagged", "OK")

      results_list[[i]] <-  list(
            sample_name = sample_name,
            PostRho = ifelse(is.null(post_rho), "NA", post_rho),
            RhoPrior = ifelse(is.null(rho_prior), "NA", rho_prior),
            Flag = ifelse(is.null(flag), "NA", flag),
            NumGenes_ZeroedOut = length(ZeroedOutGenes),
            NumGenes_HighSoupFrac = length(filtered_genes),
            HighSoupFrac_CellNumThreshold = cell_threshold,
            plot_file = paste0(sample_dir, "_SoupXestimates.png"),
            SampleResultsDir = sample_dir
          )
    } else {
      print("Skipping...")
      results_list[[i]] <-  list(
            sample_name = sample_name,
            PostRho = "NA",
            RhoPrior = "NA",
            Flag = "Skipping",
            NumGenes_ZeroedOut = "NA",
            NumGenes_HighSoupFrac = "NA",
            HighSoupFrac_CellNumThreshold = "NA",
            plot_file = "/lustre/home/harrell_lab/scRNASeq/config_slurm/no_image_available.png",
            SampleResultsDir = sample_dir
          )
    }
  }

  # Stop the parallel backend
  #stopCluster(cl)

  # Convert results to dataframe
  results_df <- do.call(rbind, lapply(results_list, as.data.frame))

  # Generate a single HTML report
  report_file <- paste0(savedir, runID, "_AmbientRNA_Contamination_report.html")
  rmarkdown::render("/lustre/home/alolex/src/WCCTR_RNASeq_Pipeline/SingleCell/AmbientRNA_Contamination_report_template.Rmd", output_file = report_file, params = list(results_df = results_df))
}

localtest = TRUE
###########################################
#### Local Testing Block
if(localtest){
  setwd("/lustre/home/harrell_lab/scRNASeq/config_slurm/06_SimpleMerge/")
  #runID <- "MultiTumorManuscript_GRCh38_250317"
  #inFile <- "/lustre/home/harrell_lab/scRNASeq/config_slurm/06_SimpleMerge/06_SeuratSimpleMerge_MultiTumorManuscript_GRCh38_250317.csv"
  #outDir <- "/lustre/home/harrell_lab/scRNASeq/config_slurm/06_SimpleMerge/"
  
  runID <- "BC003_250314"
  inFile <- "/lustre/home/harrell_lab/scRNASeq/config_slurm/06_SimpleMerge/06_SeuratSimpleMerge_BC003_250314.csv"
  outDir <- "/lustre/home/harrell_lab/scRNASeq/config_slurm/06_SimpleMerge/"
  
  features <- ""
  savedir <- paste0(outDir,runID,"_AmbientRNA_Analysis_Results/")
  numCores <- 2
  numAnchors <- 2000
  normalization <- "LogNormalize"
  mergeType <- "simple"
  parallel <- FALSE
  saveH5 <- TRUE
  species <- "human"
  regressCC <- FALSE
  exclude <- ""
  downsample <- 100
  filtercells <- TRUE
  exportCounts <- TRUE
  keep <- ""
  ambientRNAadjust <- TRUE
  regressUMI <- FALSE
  options(future.globals.maxSize = 100000 * 1024^2)
}

### Usage

## Create a directory to save all the results in
dir.create(savedir, showWarnings = FALSE)

############## PROCESS CONFIG FILE###########################
# Read in the provided config file and loop for each row.
toProcess = read.table(inFile, header=TRUE, sep=",", stringsAsFactors = FALSE)

## Subset to only saamples that had human only pipeline for testing
if(localtest){ toProcess <- toProcess[20:23,] }


print(paste(names(toProcess)))

toProcess$SeuratObj <- ""

print(paste(names(toProcess)))

print(paste(dim(toProcess)[1], " rows were found."))

generate_report(toProcess, savedir, numCores)
